{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2916999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16, ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2, VGG16, ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras.callbacks import EarlyStopping\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2626e",
   "metadata": {},
   "source": [
    "# Data preparation and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a72d47",
   "metadata": {},
   "source": [
    "This section of code is focused on setting up the necessary environment and preprocessing for training a deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527744c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4694 images belonging to 15 classes.\n",
      "Found 1165 images belonging to 15 classes.\n",
      "Found 1841 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "SEED = 1865050  \n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, filename='training.log', filemode='a', format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info(\"Starting the training script\")\n",
    "\n",
    "# Data Directories\n",
    "TRAIN_DIR = \"C:\\\\Users\\\\Pattarawadee\\\\OneDrive\\\\Desktop\\\\Master\\\\Year2\\\\Tri1\\\\DL\\\\HW\\\\2\\\\train\"\n",
    "TEST_DIR = \"C:\\\\Users\\\\Pattarawadee\\\\OneDrive\\\\Desktop\\\\Master\\\\Year2\\\\Tri1\\\\DL\\\\HW\\\\2\\\\test\"\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "logging.info(\"Data augmentation setup complete.\")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "logging.debug(\"Training generator samples: %d\", train_generator.samples)\n",
    "logging.debug(\"Validation generator samples: %d\", validation_generator.samples)\n",
    "logging.debug(\"Testing generator samples: %d\", test_generator.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e19372",
   "metadata": {},
   "source": [
    "The results indicate that the dataset has been successfully loaded and partitioned into training, validation, and testing sets, with the images being categorized into 15 different classes. Specifically:\n",
    "\n",
    "Training Set: 4694 images have been found and assigned to 15 different classes.\n",
    "Validation Set: 1165 images are present, also distributed across 15 classes.\n",
    "Testing Set: 1841 images have been identified, belonging to 15 classes as well.\n",
    "This distribution ensures that the model has a variety of data to learn from (training set), a set to tune and validate its parameters (validation set), and a different set to evaluate its final performance (testing set), all across the same 15 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda423ba",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d06d03",
   "metadata": {},
   "source": [
    "This section of the code defines the functionality for setting up three different convolutional neural network (CNN) models for image classification, as well as a mechanism to prevent overfitting during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7bbab",
   "metadata": {},
   "source": [
    "Early Stopping: An EarlyStopping callback is defined to monitor the validation loss during training. If the validation loss stops improving for 3 consecutive epochs, the training will be halted, and the model weights from the epoch with the best validation loss will be restored. This helps in preventing overfitting and ensures that the model does not waste computational resources once it ceases to learn.\n",
    "\n",
    "Model Building Functions: Three separate functions are defined to build CNN models based on different architectures, specifically MobileNetV2 (build_mobilenet_model), VGG16 (build_vgg_model), and ResNet50 (build_resnet_model). Each function follows a similar structure:\n",
    "\n",
    "Base Model: The base convolutional layer of the respective architecture is loaded with pre-trained weights from ImageNet, and its weights are set to be non-trainable. This is a form of transfer learning where the model benefits from features learned on a large dataset.\n",
    "\n",
    "Additional Layers: On top of the base model, additional layers are added including Flatten, Dense, BatchNormalisation, Activation, Dropout, and a final Dense layer. These layers are meant to adapt the learned features to the specific task at hand.\n",
    "\n",
    "Regularisation and Dropout: L2 regularisation is applied to the Dense layer and Dropout is used to prevent overfitting.\n",
    "\n",
    "Output Layer: The final Dense layer has 15 units (matching the number of classes in the dataset) and uses softmax activation to produce a probability distribution over the classes.\n",
    "\n",
    "Compilation: The model is compiled with Adam optimiser, categorical crossentropy as the loss function, and accuracy as a metric for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d8f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop training when a monitored quantity has stopped improving.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "def build_mobilenet_model():\n",
    "    base_model = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=(224, 224, 3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, kernel_regularizer=l2(1e-3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(15),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_vgg_model():\n",
    "    base_model = tf.keras.applications.VGG16(weights='imagenet', input_shape=(224, 224, 3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, kernel_regularizer=l2(1e-3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(15),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_resnet_model():\n",
    "    base_model = tf.keras.applications.ResNet50(weights='imagenet', input_shape=(224, 224, 3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, kernel_regularizer=l2(1e-3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(15),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf39a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd2946b8",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9323ab",
   "metadata": {},
   "source": [
    "This section of the code involves training three different deep learning models based on MobileNetV2, VGG16, and ResNet50 architectures for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3afc05",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21a35417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.5570 - accuracy: 0.5750\n",
      "Epoch 1: val_loss improved from inf to 1.96617, saving model to best_model_mobilenet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pattarawadee\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 248s 2s/step - loss: 2.5570 - accuracy: 0.5750 - val_loss: 1.9662 - val_accuracy: 0.7433\n",
      "Epoch 2/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.1893 - accuracy: 0.7137\n",
      "Epoch 2: val_loss did not improve from 1.96617\n",
      "147/147 [==============================] - 193s 1s/step - loss: 2.1893 - accuracy: 0.7137 - val_loss: 1.9718 - val_accuracy: 0.7605\n",
      "Epoch 3/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.0750 - accuracy: 0.7367\n",
      "Epoch 3: val_loss improved from 1.96617 to 1.94858, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 191s 1s/step - loss: 2.0750 - accuracy: 0.7367 - val_loss: 1.9486 - val_accuracy: 0.7717\n",
      "Epoch 4/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.9727 - accuracy: 0.7588\n",
      "Epoch 4: val_loss improved from 1.94858 to 1.88180, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 191s 1s/step - loss: 1.9727 - accuracy: 0.7588 - val_loss: 1.8818 - val_accuracy: 0.7794\n",
      "Epoch 5/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.8825 - accuracy: 0.7818\n",
      "Epoch 5: val_loss improved from 1.88180 to 1.81893, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 191s 1s/step - loss: 1.8825 - accuracy: 0.7818 - val_loss: 1.8189 - val_accuracy: 0.7974\n",
      "Epoch 6/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.7857 - accuracy: 0.8006\n",
      "Epoch 6: val_loss improved from 1.81893 to 1.77969, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 192s 1s/step - loss: 1.7857 - accuracy: 0.8006 - val_loss: 1.7797 - val_accuracy: 0.7725\n",
      "Epoch 7/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.7286 - accuracy: 0.8066\n",
      "Epoch 7: val_loss improved from 1.77969 to 1.70781, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 193s 1s/step - loss: 1.7286 - accuracy: 0.8066 - val_loss: 1.7078 - val_accuracy: 0.8026\n",
      "Epoch 8/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.6757 - accuracy: 0.8117\n",
      "Epoch 8: val_loss improved from 1.70781 to 1.67101, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 194s 1s/step - loss: 1.6757 - accuracy: 0.8117 - val_loss: 1.6710 - val_accuracy: 0.8069\n",
      "Epoch 9/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.6080 - accuracy: 0.8228\n",
      "Epoch 9: val_loss improved from 1.67101 to 1.61669, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 194s 1s/step - loss: 1.6080 - accuracy: 0.8228 - val_loss: 1.6167 - val_accuracy: 0.8077\n",
      "Epoch 10/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.5564 - accuracy: 0.8259\n",
      "Epoch 10: val_loss improved from 1.61669 to 1.57584, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 194s 1s/step - loss: 1.5564 - accuracy: 0.8259 - val_loss: 1.5758 - val_accuracy: 0.8026\n",
      "Epoch 11/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.5229 - accuracy: 0.8274\n",
      "Epoch 11: val_loss improved from 1.57584 to 1.54057, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 192s 1s/step - loss: 1.5229 - accuracy: 0.8274 - val_loss: 1.5406 - val_accuracy: 0.8094\n",
      "Epoch 12/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.4578 - accuracy: 0.8432\n",
      "Epoch 12: val_loss improved from 1.54057 to 1.51295, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 194s 1s/step - loss: 1.4578 - accuracy: 0.8432 - val_loss: 1.5130 - val_accuracy: 0.7974\n",
      "Epoch 13/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.4246 - accuracy: 0.8483\n",
      "Epoch 13: val_loss improved from 1.51295 to 1.45520, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 194s 1s/step - loss: 1.4246 - accuracy: 0.8483 - val_loss: 1.4552 - val_accuracy: 0.8180\n",
      "Epoch 14/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.3900 - accuracy: 0.8434\n",
      "Epoch 14: val_loss improved from 1.45520 to 1.42950, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 193s 1s/step - loss: 1.3900 - accuracy: 0.8434 - val_loss: 1.4295 - val_accuracy: 0.8240\n",
      "Epoch 15/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.3552 - accuracy: 0.8445\n",
      "Epoch 15: val_loss improved from 1.42950 to 1.40977, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 193s 1s/step - loss: 1.3552 - accuracy: 0.8445 - val_loss: 1.4098 - val_accuracy: 0.8017\n",
      "Epoch 16/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.3191 - accuracy: 0.8507\n",
      "Epoch 16: val_loss improved from 1.40977 to 1.37744, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 192s 1s/step - loss: 1.3191 - accuracy: 0.8507 - val_loss: 1.3774 - val_accuracy: 0.8060\n",
      "Epoch 17/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.2820 - accuracy: 0.8545\n",
      "Epoch 17: val_loss did not improve from 1.37744\n",
      "147/147 [==============================] - 192s 1s/step - loss: 1.2820 - accuracy: 0.8545 - val_loss: 1.3808 - val_accuracy: 0.8094\n",
      "Epoch 18/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.2566 - accuracy: 0.8558\n",
      "Epoch 18: val_loss improved from 1.37744 to 1.33198, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 194s 1s/step - loss: 1.2566 - accuracy: 0.8558 - val_loss: 1.3320 - val_accuracy: 0.8129\n",
      "Epoch 19/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.2255 - accuracy: 0.8679\n",
      "Epoch 19: val_loss improved from 1.33198 to 1.31181, saving model to best_model_mobilenet.h5\n",
      "147/147 [==============================] - 193s 1s/step - loss: 1.2255 - accuracy: 0.8679 - val_loss: 1.3118 - val_accuracy: 0.8197\n",
      "Epoch 20/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.2067 - accuracy: 0.8690\n",
      "Epoch 20: val_loss did not improve from 1.31181\n",
      "147/147 [==============================] - 191s 1s/step - loss: 1.2067 - accuracy: 0.8690 - val_loss: 1.3349 - val_accuracy: 0.8017\n"
     ]
    }
   ],
   "source": [
    "# Train MobileNetV2 Model\n",
    "# Building the MobileNetV2 model\n",
    "mnV2_model = build_mobilenet_model()\n",
    "\n",
    "# Setting up a checkpoint to save the best version of the model based on validation loss\n",
    "mnV2_cp = ModelCheckpoint(filepath='best_model_mobilenet.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "# Configuring TensorBoard for logging training statistics in the 'mobilenet' directory\n",
    "mnV2_tb = TensorBoard(log_dir=os.path.join(os.getcwd(), 'logs/mobilenet'))\n",
    "\n",
    "# Training the MobileNetV2 model with early stopping, model checkpoint, and TensorBoard callbacks\n",
    "mnV2_history = mnV2_model.fit(train_generator, validation_data=validation_generator, epochs=20, callbacks=[early_stopping, mnV2_cp, mnV2_tb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72238bf0",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54dddb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 3.0819 - accuracy: 0.3530\n",
      "Epoch 1: val_loss improved from inf to 2.65903, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 725s 5s/step - loss: 3.0819 - accuracy: 0.3530 - val_loss: 2.6590 - val_accuracy: 0.5262\n",
      "Epoch 2/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.6176 - accuracy: 0.5096\n",
      "Epoch 2: val_loss improved from 2.65903 to 2.38065, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 717s 5s/step - loss: 2.6176 - accuracy: 0.5096 - val_loss: 2.3806 - val_accuracy: 0.5906\n",
      "Epoch 3/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.4567 - accuracy: 0.5616\n",
      "Epoch 3: val_loss improved from 2.38065 to 2.29273, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 730s 5s/step - loss: 2.4567 - accuracy: 0.5616 - val_loss: 2.2927 - val_accuracy: 0.6300\n",
      "Epoch 4/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.3364 - accuracy: 0.5929\n",
      "Epoch 4: val_loss improved from 2.29273 to 2.20523, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 719s 5s/step - loss: 2.3364 - accuracy: 0.5929 - val_loss: 2.2052 - val_accuracy: 0.6455\n",
      "Epoch 5/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.2401 - accuracy: 0.6206\n",
      "Epoch 5: val_loss improved from 2.20523 to 2.15238, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 743s 5s/step - loss: 2.2401 - accuracy: 0.6206 - val_loss: 2.1524 - val_accuracy: 0.6403\n",
      "Epoch 6/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.1703 - accuracy: 0.6280\n",
      "Epoch 6: val_loss improved from 2.15238 to 2.10854, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 731s 5s/step - loss: 2.1703 - accuracy: 0.6280 - val_loss: 2.1085 - val_accuracy: 0.6524\n",
      "Epoch 7/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.1124 - accuracy: 0.6393\n",
      "Epoch 7: val_loss improved from 2.10854 to 2.06635, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 734s 5s/step - loss: 2.1124 - accuracy: 0.6393 - val_loss: 2.0664 - val_accuracy: 0.6549\n",
      "Epoch 8/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.0595 - accuracy: 0.6449\n",
      "Epoch 8: val_loss improved from 2.06635 to 2.00285, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 719s 5s/step - loss: 2.0595 - accuracy: 0.6449 - val_loss: 2.0028 - val_accuracy: 0.6824\n",
      "Epoch 9/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.0081 - accuracy: 0.6621\n",
      "Epoch 9: val_loss improved from 2.00285 to 1.91677, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 734s 5s/step - loss: 2.0081 - accuracy: 0.6621 - val_loss: 1.9168 - val_accuracy: 0.7047\n",
      "Epoch 10/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.9564 - accuracy: 0.6653\n",
      "Epoch 10: val_loss improved from 1.91677 to 1.90819, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 730s 5s/step - loss: 1.9564 - accuracy: 0.6653 - val_loss: 1.9082 - val_accuracy: 0.6841\n",
      "Epoch 11/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.9039 - accuracy: 0.6792\n",
      "Epoch 11: val_loss improved from 1.90819 to 1.88279, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 739s 5s/step - loss: 1.9039 - accuracy: 0.6792 - val_loss: 1.8828 - val_accuracy: 0.6867\n",
      "Epoch 12/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.8620 - accuracy: 0.6870\n",
      "Epoch 12: val_loss improved from 1.88279 to 1.83879, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 738s 5s/step - loss: 1.8620 - accuracy: 0.6870 - val_loss: 1.8388 - val_accuracy: 0.6927\n",
      "Epoch 13/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.8206 - accuracy: 0.6932\n",
      "Epoch 13: val_loss did not improve from 1.83879\n",
      "147/147 [==============================] - 728s 5s/step - loss: 1.8206 - accuracy: 0.6932 - val_loss: 1.8483 - val_accuracy: 0.6850\n",
      "Epoch 14/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.7785 - accuracy: 0.6994\n",
      "Epoch 14: val_loss improved from 1.83879 to 1.77002, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 728s 5s/step - loss: 1.7785 - accuracy: 0.6994 - val_loss: 1.7700 - val_accuracy: 0.6979\n",
      "Epoch 15/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.7529 - accuracy: 0.7084\n",
      "Epoch 15: val_loss improved from 1.77002 to 1.73294, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 740s 5s/step - loss: 1.7529 - accuracy: 0.7084 - val_loss: 1.7329 - val_accuracy: 0.7142\n",
      "Epoch 16/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.7101 - accuracy: 0.7128\n",
      "Epoch 16: val_loss improved from 1.73294 to 1.72945, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 750s 5s/step - loss: 1.7101 - accuracy: 0.7128 - val_loss: 1.7295 - val_accuracy: 0.7082\n",
      "Epoch 17/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.6706 - accuracy: 0.7224\n",
      "Epoch 17: val_loss improved from 1.72945 to 1.68882, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 719s 5s/step - loss: 1.6706 - accuracy: 0.7224 - val_loss: 1.6888 - val_accuracy: 0.7167\n",
      "Epoch 18/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.6731 - accuracy: 0.7035\n",
      "Epoch 18: val_loss did not improve from 1.68882\n",
      "147/147 [==============================] - 720s 5s/step - loss: 1.6731 - accuracy: 0.7035 - val_loss: 1.7051 - val_accuracy: 0.7039\n",
      "Epoch 19/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.6225 - accuracy: 0.7258\n",
      "Epoch 19: val_loss did not improve from 1.68882\n",
      "147/147 [==============================] - 733s 5s/step - loss: 1.6225 - accuracy: 0.7258 - val_loss: 1.7018 - val_accuracy: 0.6850\n",
      "Epoch 20/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.6138 - accuracy: 0.7186\n",
      "Epoch 20: val_loss improved from 1.68882 to 1.65364, saving model to best_model_vgg.h5\n",
      "147/147 [==============================] - 738s 5s/step - loss: 1.6138 - accuracy: 0.7186 - val_loss: 1.6536 - val_accuracy: 0.7133\n"
     ]
    }
   ],
   "source": [
    "# Train VGG16 Model\n",
    "# Building the VGG16 model\n",
    "vgg16_model = build_vgg_model()\n",
    "\n",
    "# Setting up a checkpoint to save the best version of the model based on validation loss\n",
    "vgg16_cp = ModelCheckpoint(filepath='best_model_vgg.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "# Configuring TensorBoard for logging training statistics in the 'vgg' directory\n",
    "vgg16_tb = TensorBoard(log_dir=os.path.join(os.getcwd(), 'logs/vgg'))\n",
    "\n",
    "# Training the VGG16 model with early stopping, model checkpoint, and TensorBoard callbacks\n",
    "vgg16_history = vgg16_model.fit(train_generator, validation_data=validation_generator, epochs=20, callbacks=[early_stopping, vgg16_cp, vgg16_tb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161181be",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "597df573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 3.0241 - accuracy: 0.1525\n",
      "Epoch 1: val_loss improved from inf to 3.56068, saving model to best_model_resnet.h5\n",
      "147/147 [==============================] - 445s 3s/step - loss: 3.0241 - accuracy: 0.1525 - val_loss: 3.5607 - val_accuracy: 0.1227\n",
      "Epoch 2/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.7154 - accuracy: 0.1939\n",
      "Epoch 2: val_loss improved from 3.56068 to 2.83089, saving model to best_model_resnet.h5\n",
      "147/147 [==============================] - 444s 3s/step - loss: 2.7154 - accuracy: 0.1939 - val_loss: 2.8309 - val_accuracy: 0.1725\n",
      "Epoch 3/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.6386 - accuracy: 0.2118\n",
      "Epoch 3: val_loss improved from 2.83089 to 2.75416, saving model to best_model_resnet.h5\n",
      "147/147 [==============================] - 435s 3s/step - loss: 2.6386 - accuracy: 0.2118 - val_loss: 2.7542 - val_accuracy: 0.2017\n",
      "Epoch 4/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.6019 - accuracy: 0.2196\n",
      "Epoch 4: val_loss did not improve from 2.75416\n",
      "147/147 [==============================] - 432s 3s/step - loss: 2.6019 - accuracy: 0.2196 - val_loss: 2.7573 - val_accuracy: 0.1648\n",
      "Epoch 5/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.5438 - accuracy: 0.2273\n",
      "Epoch 5: val_loss improved from 2.75416 to 2.57932, saving model to best_model_resnet.h5\n",
      "147/147 [==============================] - 450s 3s/step - loss: 2.5438 - accuracy: 0.2273 - val_loss: 2.5793 - val_accuracy: 0.2300\n",
      "Epoch 6/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.5226 - accuracy: 0.2301\n",
      "Epoch 6: val_loss did not improve from 2.57932\n",
      "147/147 [==============================] - 444s 3s/step - loss: 2.5226 - accuracy: 0.2301 - val_loss: 2.6352 - val_accuracy: 0.1854\n",
      "Epoch 7/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.4988 - accuracy: 0.2444\n",
      "Epoch 7: val_loss improved from 2.57932 to 2.49098, saving model to best_model_resnet.h5\n",
      "147/147 [==============================] - 449s 3s/step - loss: 2.4988 - accuracy: 0.2444 - val_loss: 2.4910 - val_accuracy: 0.2352\n",
      "Epoch 8/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.4759 - accuracy: 0.2524\n",
      "Epoch 8: val_loss did not improve from 2.49098\n",
      "147/147 [==============================] - 433s 3s/step - loss: 2.4759 - accuracy: 0.2524 - val_loss: 2.7645 - val_accuracy: 0.2129\n",
      "Epoch 9/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.4705 - accuracy: 0.2588\n",
      "Epoch 9: val_loss did not improve from 2.49098\n",
      "147/147 [==============================] - 440s 3s/step - loss: 2.4705 - accuracy: 0.2588 - val_loss: 2.5381 - val_accuracy: 0.2155\n",
      "Epoch 10/20\n",
      "147/147 [==============================] - ETA: 0s - loss: 2.4511 - accuracy: 0.2648\n",
      "Epoch 10: val_loss did not improve from 2.49098\n",
      "147/147 [==============================] - 435s 3s/step - loss: 2.4511 - accuracy: 0.2648 - val_loss: 2.6282 - val_accuracy: 0.1760\n"
     ]
    }
   ],
   "source": [
    "# Train ResNet50 Model\n",
    "# Building the ResNet50 model\n",
    "res50_model = build_resnet_model()\n",
    "\n",
    "# Setting up a checkpoint to save the best version of the model based on validation loss\n",
    "res50_cp = ModelCheckpoint(filepath='best_model_resnet.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "# Configuring TensorBoard for logging training statistics in the 'resnet' directory\n",
    "res50_tb = TensorBoard(log_dir=os.path.join(os.getcwd(), 'logs/resnet'))\n",
    "\n",
    "# Training the ResNet50 model with early stopping, model checkpoint, and TensorBoard callbacks\n",
    "res50_history = res50_model.fit(train_generator, validation_data=validation_generator, epochs=20, callbacks=[early_stopping, res50_cp, res50_tb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771499f",
   "metadata": {},
   "source": [
    "# Visualising Training Metrics with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b074156f",
   "metadata": {},
   "source": [
    "This section is dedicated to utilising TensorBoard, a comprehensive visualisation tool from TensorFlow's ecosystem, to monitor and assess the training metrics of deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e694302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cad8774b1fd6272a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cad8774b1fd6272a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enabling TensorBoard within Jupyter Notebooks\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Starting TensorBoard and specifying the directory where the logs are stored\n",
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c4d33",
   "metadata": {},
   "source": [
    "# Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055f5de",
   "metadata": {},
   "source": [
    "In this section, the pre-trained models from different architectural backgrounds, specifically VGG, ResNet, and MobileNetV2, are thoroughly evaluated on the test dataset to understand their performance in testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e79d135e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vgg': 0.7327539324760437,\n",
       " 'resnet': 0.2927756607532501,\n",
       " 'mobilenet': 0.8413905501365662}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the architecture names using abbreviations\n",
    "arch_names = ['VGG', 'ResNet', 'MobileNetV2']\n",
    "\n",
    "# Initializing a dictionary to hold the loaded models\n",
    "loaded_models = {}\n",
    "\n",
    "# Loading the pre-trained models for each architecture\n",
    "# 'best_model_vgg.h5', 'best_model_resnet.h5', 'best_model_mobilenet.h5'\n",
    "for architecture in arch_names:\n",
    "    model_filepath = f'best_model_{architecture.lower()}.h5'\n",
    "    loaded_models[architecture] = load_model(model_filepath)\n",
    "\n",
    "# Evaluate each loaded model on the test dataset and store the accuracy in a dictionary\n",
    "test_accuracies = {}\n",
    "\n",
    "# Iterating through the loaded models for evaluation\n",
    "for architecture, loaded_model in loaded_models.items():\n",
    "    _, accuracy = loaded_model.evaluate(test_generator, verbose=0)\n",
    "    test_accuracies[architecture] = accuracy\n",
    "\n",
    "# Displaying the accuracy results for each architecture\n",
    "test_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3320fbe",
   "metadata": {},
   "source": [
    "The performance evaluation of the VGG, ResNet, and MobileNetV2 models on the test dataset has yielded the following accuracy results:\n",
    "\n",
    "VGG: 73.28%\n",
    "ResNet: 29.28%\n",
    "MobileNetV2: 84.14%\n",
    "\n",
    "\n",
    "These results indicate that the MobileNetV2 model outperformed the other two models by a significant margin. On the other hand, the ResNet model showed a surprisingly low accuracy, which might be indicative of issues during training or a mismatch in the problem complexity and model capacity. It could also be due to the model not being fine-tuned adequately for the given task. The VGG model achieved a respectable accuracy, showcasing its strong feature extraction capabilities, though it could not surpass the MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669bb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
